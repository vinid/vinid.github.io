[{"authors":null,"categories":null,"content":"Hello! I am Federico Bianchi, a post-doctoral researcher at Bocconi University (with Prof. Dirk Hovy), Milan, Italy.\nYou can find my work in the main track of different AI venues (e.g., NAACL, EACL, AAAI, ACL, ISWC, RecSys) and Q1 Journals (e.g., Cognitive Science, Nature PJQI, SWJ) and a few things have also been featured in press or in company media outlets (see, 1, 2, 3, 4).\nI have different interests that range from neuro-symbolic learning and reasoning to natural language processing and from quantum physics to deep learning for the e-commerce.\nI have also worked/collaborated with companies: I have collaborated as a Data Scientist for Instal LLC and I have an ongoing research collaboration with people at Coveo on e-commerce and recommendation research. In the past, I worked as a full-stack software developer for Mobave LLC (later acquired by Instal) and for Whattaspot.\n","date":1614643200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1614643200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hello! I am Federico Bianchi, a post-doctoral researcher at Bocconi University (with Prof. Dirk Hovy), Milan, Italy.\nYou can find my work in the main track of different AI venues (e.","tags":null,"title":"Federico Bianchi","type":"authors"},{"authors":["Federico Bianchi","Adriano Macarone"],"categories":null,"content":"","date":1616504400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616504400,"objectID":"96104981d75926385caf4dfaeb23d788","permalink":"https://federicobianchi.io/talk/deep-learning-for-quantum-problems/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/talk/deep-learning-for-quantum-problems/","section":"event","summary":"We introduce the main components present in deep learning architecture and the possible applications in quantum physics.","tags":[],"title":"Deep Learning for Quantum Problems","type":"event"},{"authors":["Federico Bianchi"],"categories":null,"content":"","date":1616504400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616504400,"objectID":"08bf1e083c062f3d6aeb744275bc2362","permalink":"https://federicobianchi.io/talk/fantastic-embeddings-and-how-to-align-them-zero-shot-inference-in-a-multi-shop-scenario/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/talk/fantastic-embeddings-and-how-to-align-them-zero-shot-inference-in-a-multi-shop-scenario/","section":"event","summary":"In this talk I present our paper on aligning product embeddings that come from multiple shops. We use techniques from machine translation to provide an effective method for alignment.","tags":[],"title":"Fantastic Embeddings and How to Align Them: Zero-Shot Inference in a Multi-Shop Scenario","type":"event"},{"authors":["Federico Bianchi","Ciro Greco","Jacopo Tagliabue"],"categories":null,"content":"","date":1614643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614643200,"objectID":"d63fa74bda8dcedf3e9101f5944a969d","permalink":"https://federicobianchi.io/publication/language-in-a-search-box/","publishdate":"2021-03-02T00:00:00Z","relpermalink":"/publication/language-in-a-search-box/","section":"publication","summary":"We investigate grounded language learning through real-world data, by modelling a teacher-learner dynamics through the natural interactions occurring between users and search engines.","tags":[],"title":"Language in a (Search) Box: Grounding Language Learning in Real-World Human-Machine Interaction","type":"publication"},{"authors":["Tommaso Fornaciari","Federico Bianchi","Massimo Poesio","Dirk Hovy"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"18d710d1bd07ff373dffa9c27d29a89b","permalink":"https://federicobianchi.io/publication/bertective/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/bertective/","section":"publication","summary":"Spotting a lie is challenging but has an enormous potential impact on security as well as private and public safety. Several NLP methods have been proposed to classify texts as truthful or deceptive. In most cases, however, the target texts' preceding context is not considered. This is a severe limitation, as any communication takes place in context, not in a vacuum, and context can help to detect deception. We study a corpus of Italian dialogues containing deceptive statements and implement deep neural models that incorporate various linguistic contexts. We establish a new state-of-the-art identifying deception and find that not all context is equally useful to the task. Only the texts closest to the target, if from the same speaker (rather than questions by an interlocutor), boost performance. We also find that the semantic information in language models such as BERT contributes to the performance. However, BERT alone does not capture the implicit knowledge of deception cues: its contribution is conditional on the concurrent use of attention to learn cues from BERT's representations.","tags":[],"title":"BERTective: Language Models and Contextual Information for Deception Detection","type":"publication"},{"authors":["Federico Bianchi","Silvia Terragni","Dirk Hovy","Debora Nozza","Elisabetta Fersini"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"1aea40578aaeb79054905662a2c0203a","permalink":"https://federicobianchi.io/publication/cross-lingual-contextualized-topic-models-for-zero-shot/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/cross-lingual-contextualized-topic-models-for-zero-shot/","section":"publication","summary":"We introduce a novel topic modeling method that can make use of contextulized embeddings (e.g., BERT) to do zero-shot cross-lingual topic modeling.","tags":[],"title":"Cross-lingual Contextualized Topic Models with Zero-shot Learning","type":"publication"},{"authors":["Federico Bianchi","Silvia Terragni","Dirk Hovy"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"127db8331089b31160f6db4060863e21","permalink":"https://federicobianchi.io/publication/pre-training-is-a-hot-topic/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/pre-training-is-a-hot-topic/","section":"publication","summary":"We introduce a novel topic modeling method that can provide highly coherent topics thanks to the use of contextualized embeddings.","tags":[],"title":"Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence","type":"publication"},{"authors":["Federico Bianchi"],"categories":null,"content":"","date":1613566800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613566800,"objectID":"f962e0e4405e52f2de6ccd416d10f4b4","permalink":"https://federicobianchi.io/talk/learning-jax-for-great-good/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/talk/learning-jax-for-great-good/","section":"event","summary":"I gave a tutorial on JAX,  the new google framework for deep learning. I have described how to compute simple derivatives and finished describing some applications in NLP.","tags":[],"title":"Learning JAX for Great Good","type":"event"},{"authors":["Monireh Ebrahimi","Aaron Eberhart","Federico Bianchi","Pascal Hitzler"],"categories":null,"content":"","date":1612569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612569600,"objectID":"4164406b0bb8bbc9dfdbd1d672bb4f81","permalink":"https://federicobianchi.io/publication/towards-neuro-symbolic/","publishdate":"2021-02-06T00:00:00Z","relpermalink":"/publication/towards-neuro-symbolic/","section":"publication","summary":"Symbolic knowledge representation and reasoning and deep learning are fundamentally different approaches to artificial intelligence with complementary capabilities. The former are transparent and data-efficient, but they are sensitive to noise and cannot be applied to non-symbolic domains where the data is ambiguous. The latter can learn complex tasks from examples, are robust to noise, but are black boxes; require large amounts of –not necessarily easily obtained– data, and are slow to learn and prone to adversarial examples. Either paradigm excels at certain types of problems where the other paradigm performs poorly. In order to develop stronger AI systems, integrated neuro-symbolic systems that combine artificial neural networks and symbolic reasoning are being sought. In this context, one of the fundamental open problems is how to perform logic-based deductive reasoning over knowledge bases by means of trainable artificial neural networks. This paper provides a brief summary of the authors’ recent efforts to bridge the neural and symbolic divide in the context of deep deductive reasoners. Throughout the paper we will discuss strengths and limitations of models in term of accuracy, scalability, transferability, generalizabiliy, speed, and interpretability, and finally, will talk about possible modifications to enhance desirable capabilities. More specifically, in terms of architectures, we are looking at Memory-augmented networks, Logic Tensor Networks, and compositions of LSTM models to explore their capabilities and limitations in conducting deductive reasoning. We are applying these models on Resource Description Framework (RDF), first-order logic, and the description logic EL+ respectively.","tags":[],"title":"Towards bridging the neuro-symbolic gap: deep deductive reasoners.","type":"publication"},{"authors":["Federico Bianchi","吳恩達"],"categories":["Demo","教程"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://federicobianchi.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Federico Bianchi"],"categories":null,"content":"","date":1602075600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602075600,"objectID":"1d1425392e64fd4f405da4d73da5d418","permalink":"https://federicobianchi.io/talk/vector-space-alignment-for-semantic-change-analysis/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/talk/vector-space-alignment-for-semantic-change-analysis/","section":"event","summary":"The use of compass aligned embeddings for semantic change analysis.","tags":[],"title":"Vector Space Alignment for Semantic Change Analysis","type":"event"},{"authors":["Federico Bianchi","Jacopo Tagliabue","Bingqing Yu","Luca Bigon","Ciro Greco"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"54386415eda7e67500d2fe9d55ce8989","permalink":"https://federicobianchi.io/publication/fantasitc-embeddings/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/fantasitc-embeddings/","section":"publication","summary":"In this paper we work on aligning product embeddings that come from different shops. We use techniques from machine translation to provide an effective method for alignment.","tags":[],"title":"Fantastic Embeddings and How to Align Them: Zero-Shot Inference in a Multi-Shop Scenario","type":"publication"},{"authors":["Federico Bianchi"],"categories":null,"content":"","date":1551445200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551445200,"objectID":"b820420e29d21b112d912bf43c8769fc","permalink":"https://federicobianchi.io/talk/on-the-capabilities-of-logic-tensor-networks-for-deductive-reasoning/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/talk/on-the-capabilities-of-logic-tensor-networks-for-deductive-reasoning/","section":"event","summary":"I presented our work on Logic Tensor Networks, where we explore its reasoning capabilities.","tags":[],"title":"On the Capabilities of Logic Tensor Networks for Deductive Reasoning","type":"event"},{"authors":["Federico Bianchi","Matteo Palmonari","Debora Nozza"],"categories":null,"content":"","date":1530489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530489600,"objectID":"3b401328c412d7509d701786182012cd","permalink":"https://federicobianchi.io/publication/towards-encoding-time/","publishdate":"2018-07-02T00:00:00Z","relpermalink":"/publication/towards-encoding-time/","section":"publication","summary":"Knowledge Graphs (KG) are widely used abstractions to represent entity-centric knowledge. Approaches to embed entities, entity types and relations represented in the graph into vector spaces - often referred to as KG embeddings - have become increasingly popular for their ability to capture the similarity between entities and support other reasoning tasks. However, representation of time has received little attention in these approaches. In this work, we make a first step to encode time into vector-based entity representations using a text-based KG embedding model named Typed Entity Embeddings (TEEs). In TEEs, each entity is represented by a vector that represents the entity and its type, which is learned from entity mentions found in a text corpus. Inspired by evidence from cognitive sciences and application-oriented concerns, we propose an approach to encode representations of years into TEEs by aggregating the representations of the entities that occur in event-based descriptions of the years. These representations are used to define two time-aware similarity measures to control the implicit effect of time on entity similarity. Experimental results show that the linear order of years obtained using our model is highly correlated with natural time flow and the effectiveness of the time-aware similarity measure proposed to flatten the time effect on entity similarity","tags":[],"title":"Towards Encoding Time in text-based Entity Embeddings","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://federicobianchi.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]